<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website (Posts about statistics)</title><link>https://austintripp.ca/</link><description></description><atom:link href="https://austintripp.ca/categories/statistics.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Mon, 14 Apr 2025 08:35:16 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Problems with the top-k diversity metric for diverse optimization</title><link>https://austintripp.ca/blog/2024-10-07-problems-with-topk-diversity/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered" id="cell-id=b4485680-e872-4498-b53b-cfc0bcde2315"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="alert alert-block alert-info"&gt;
&lt;b&gt;NOTE&lt;/b&gt;
    this blog post can be run as a jupyter notebook. I re-ordered the cells to make it easier to read; to re-produce all the plots see instructions at the end of the post.
&lt;/div&gt;
&lt;h3 id="Background"&gt;Background&lt;a class="anchor-link" href="https://austintripp.ca/blog/2024-10-07-problems-with-topk-diversity/#Background"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;em&gt;"Diverse optimization"&lt;/em&gt; has been a popular topic in machine learning conferences
for a few years now, particularly in the "AI for drug discovery" sub-field.
In this context, the goal of "optimization" algorithms is to suggest
promising drug candidates,
where "promising" means maximizing one (or more) objective functions.
An example of an objective function could be a docking score
(an approximate simulation of the interactions between a protein and a molecule).
"Diverse" optimization further requires that an algorithm produce multiple
distinct candidate solutions.
This is typically desired when the objective functions don't fully capture
everything we want (for example, a drug candidate also having low toxicity).
The hope is that a diverse set of candidates will have a higher chance of
one useful candidate compared to a non-diverse sets.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-10-07-problems-with-topk-diversity/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>machine learning</category><category>statistics</category><guid>https://austintripp.ca/blog/2024-10-07-problems-with-topk-diversity/</guid><pubDate>Mon, 07 Oct 2024 00:00:00 GMT</pubDate></item><item><title>The Monty Hall Problem is Really About Policy Assumptions</title><link>https://austintripp.ca/blog/2020/02/10/monty-hall/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: the Monty Hall problem doesn't have a well-defined solution.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2020/02/10/monty-hall/"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>frontpage</category><category>statistics</category><guid>https://austintripp.ca/blog/2020/02/10/monty-hall/</guid><pubDate>Mon, 10 Feb 2020 00:00:00 GMT</pubDate></item><item><title>Why you should never be certain of your beliefs: a Bayesian perspective</title><link>https://austintripp.ca/blog/2018/08/21/bayes-no-certain-priors/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;People are notoriously bad at estimating their percent confidence in their beliefs, as explained further in this &lt;a href="https://en.wikipedia.org/wiki/Overconfidence_effect"&gt;Wikipedia article&lt;/a&gt;. 
Something I thought of recently is what effect this overconfidence has from a Bayesian perspective. 
After a bit of math, I came to the conclusion that having extreme confidence in your beliefs (0% or 100% confidence) implies that you would be unable to change your beliefs if shown evidence to the contrary.
I believe this simple argument suggests that it is very irrational to hold prior beliefs of 0 or 100%. If you do feel this way, then you should choose a very high value (99.99%) or a very low value (0.001%), but always leave some room for error.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2018/08/21/bayes-no-certain-priors/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>decision making</category><category>frontpage</category><category>statistics</category><guid>https://austintripp.ca/blog/2018/08/21/bayes-no-certain-priors/</guid><pubDate>Tue, 21 Aug 2018 00:00:00 GMT</pubDate></item></channel></rss>
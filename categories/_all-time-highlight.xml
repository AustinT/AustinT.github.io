<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website (Posts about _all-time-highlight)</title><link>https://austintripp.ca/</link><description></description><atom:link href="https://austintripp.ca/categories/_all-time-highlight.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2026 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Sun, 04 Jan 2026 14:41:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Blogging in the LLM age: a second golden age for blogs?</title><link>https://austintripp.ca/blog/2025-06-23-blog-in-llm-age/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;LLMs (large language models) are currently scraping &lt;em&gt;all&lt;/em&gt; text on the public
internet, training on it, and spitting out variants of that text in response to
queries. I think this fact makes now a &lt;em&gt;golden age&lt;/em&gt; for blog writing. If you
have ever thought about writing a blog, the time is now.&lt;/p&gt;
&lt;p&gt;This idea is not unique or original&lt;sup id="fnref:gwern"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-06-23-blog-in-llm-age/#fn:gwern"&gt;1&lt;/a&gt;&lt;/sup&gt;, but I am completely convinced by it. The
purpose of this post is to explain it in my own words.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-06-23-blog-in-llm-age/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>_all-time-highlight</category><category>blog</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-06-23-blog-in-llm-age/</guid><pubDate>Mon, 23 Jun 2025 00:00:00 GMT</pubDate></item><item><title>Overview of the NSGA-II algorithm for multi-objective optimization</title><link>https://austintripp.ca/blog/2024-11-04-nsga-ii/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Nondominated sorting genetic algorithm version 2,
more commonly called NSGA-II, is a well-established genetic algorithm
(aka evolutionary algorithm)
for multi-objective optimization (MOO).
In this post I try to extract the key insights/lessons from this paper.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-11-04-nsga-ii/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>_all-time-highlight</category><category>research papers</category><guid>https://austintripp.ca/blog/2024-11-04-nsga-ii/</guid><pubDate>Mon, 04 Nov 2024 00:00:00 GMT</pubDate></item><item><title>Why you should never be certain of your beliefs: a Bayesian perspective</title><link>https://austintripp.ca/blog/2018/08/21/bayes-no-certain-priors/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;People are notoriously bad at estimating their percent confidence in their beliefs, as explained further in this &lt;a href="https://en.wikipedia.org/wiki/Overconfidence_effect"&gt;Wikipedia article&lt;/a&gt;. 
Something I thought of recently is what effect this overconfidence has from a Bayesian perspective. 
After a bit of math, I came to the conclusion that having extreme confidence in your beliefs (0% or 100% confidence) implies that you would be unable to change your beliefs if shown evidence to the contrary.
I believe this simple argument suggests that it is very irrational to hold prior beliefs of 0 or 100%. If you do feel this way, then you should choose a very high value (99.99%) or a very low value (0.001%), but always leave some room for error.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2018/08/21/bayes-no-certain-priors/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>_all-time-highlight</category><category>decision making</category><category>statistics</category><guid>https://austintripp.ca/blog/2018/08/21/bayes-no-certain-priors/</guid><pubDate>Tue, 21 Aug 2018 00:00:00 GMT</pubDate></item></channel></rss>
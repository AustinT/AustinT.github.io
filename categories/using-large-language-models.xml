<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website (Posts about using large language models)</title><link>https://austintripp.ca/</link><description></description><atom:link href="https://austintripp.ca/categories/using-large-language-models.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Tue, 01 Apr 2025 09:47:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Using LLMs to improve my Chinese</title><link>https://austintripp.ca/blog/2025-03-30-llms-improve-chinese/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been learning Chinese for almost 10 years now, but still make
awkward-sounding sentences when I speak. A few months ago I thought "why not
use LLMs to help me speak more naturally", and found that it does not take much
prompting to get useful feedback. Here is a conversation with Claude 3.5 from a
few months ago:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-03-30-llms-improve-chinese/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>chinese</category><category>language</category><category>using large language models</category><guid>https://austintripp.ca/blog/2025-03-30-llms-improve-chinese/</guid><pubDate>Sun, 30 Mar 2025 00:00:00 GMT</pubDate></item><item><title>Alpha over LLMs</title><link>https://austintripp.ca/blog/2025-02-24-llm-alpha/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;p&gt;On a recent podcast, &lt;a href="https://www.kalzumeus.com/about/"&gt;Patrick McKenzie&lt;/a&gt;
mentioned the idea of "alpha over LLMs": does a publisher produce text with any
meaningful advantage over asking an LLM? I think this is an important question
for anybody trying to regularly write, even if the readership is small (eg this
blog). I interpret this as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;People should not put out content which is obviously wrong and can be
  corrected by an LLM (eg "I have theory X" where asking an LLM provides clear
  and convincing counter-arguments to X).&lt;/li&gt;
&lt;li&gt;People should also not put out content which is worse than the answer you get
  from asking an LLM (eg the same content but explained less clearly).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will generally try to uphold this principle in future blog posts.&lt;/p&gt;</description><category>announcement</category><category>blog</category><category>using large language models</category><guid>https://austintripp.ca/blog/2025-02-24-llm-alpha/</guid><pubDate>Mon, 24 Feb 2025 00:00:00 GMT</pubDate></item></channel></rss>
<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website (Posts about opinion)</title><link>https://austintripp.ca/</link><description></description><atom:link href="https://austintripp.ca/categories/opinion.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2026 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Sun, 01 Feb 2026 12:17:09 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>We have forgotten about utility functions in BO (whoops!)</title><link>https://austintripp.ca/blog/2026-01-27-forgotten-utility-bo/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Bayesian decision theory is one of the best justifications for BO- particularly
for myopic acquisition functions like expected improvement. However, these
acquisition functions are only "optimal" if one's utility function is $u(y) =
y$ (the identity function). Have BO researchers (and BO users) basically
&lt;em&gt;forgotten&lt;/em&gt; to swap this out for "real" utility functions in practice? In this
post I argue that we have basically overlooked this detail (to our own
detriment). It's not &lt;em&gt;too&lt;/em&gt; hard to fix, but unfortunately the $u(y) = y$
assumption is actually quite deeply embedded, and completely removing it will
make things more complicated. Ultimately, despite the difficulty, I think we
should do it anyway.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2026-01-27-forgotten-utility-bo/"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>_recent-highlight</category><category>bayesian optimization</category><category>machine learning</category><category>opinion</category><guid>https://austintripp.ca/blog/2026-01-27-forgotten-utility-bo/</guid><pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate></item><item><title>My model-centric view of Bayesian optimization</title><link>https://austintripp.ca/blog/2026-01-25-model-centric-bo/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;A lot of conversations at NeurIPS this year made me think that I view the role
of the surrogate model in Bayesian optimization a bit differently than many
other researchers in the field, and this profoundly impacts my view of many
other aspects of BO. Therefore, the purpose of this post is to explain my view
and contrast it with what I believe is the more mainstream view.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2026-01-25-model-centric-bo/"&gt;Read more…&lt;/a&gt; (17 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>_recent-highlight</category><category>bayesian optimization</category><category>machine learning</category><category>opinion</category><guid>https://austintripp.ca/blog/2026-01-25-model-centric-bo/</guid><pubDate>Sun, 25 Jan 2026 22:00:00 GMT</pubDate></item><item><title>Thoughts on writing PhD reference letters.</title><link>https://austintripp.ca/blog/2025-12-30-phd-reference-letter/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;2025 was the first year where I wrote reference letters for research students
who I supervised. In this post I will explain my strategy towards writing
letters and how students can best support this. Feedback is welcome (especially
from more senior people who've written many letters).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-12-30-phd-reference-letter/"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>employment</category><category>opinion</category><category>PhD</category><guid>https://austintripp.ca/blog/2025-12-30-phd-reference-letter/</guid><pubDate>Tue, 30 Dec 2025 00:00:00 GMT</pubDate></item><item><title>Why listen to podcasts?</title><link>https://austintripp.ca/blog/2025-11-16-why-podcasts/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Although everybody seems to listen to podcasts these days, some people do not,
and I've found myself explaining several times why I choose to listen to them
(as opposed to just listening to music or audiobooks). This post is essentially
my stock response.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-11-16-why-podcasts/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>opinion</category><guid>https://austintripp.ca/blog/2025-11-16-why-podcasts/</guid><pubDate>Sun, 16 Nov 2025 00:00:00 GMT</pubDate></item><item><title>Justifying expected utility maximization from first principles (Von Neumann–Morgenstern).</title><link>https://austintripp.ca/blog/2025-11-02-expected-utility/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I've recently found myself arguing for expected utility maximization as an
approach to practical decision making problems at work (mostly regarding
molecule selection). This post is my attempt to write out an argument for using
expected utility, targeted at non-mathematical (but still technical) readers.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-11-02-expected-utility/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>_recent-highlight</category><category>machine learning</category><category>opinion</category><category>statistics</category><guid>https://austintripp.ca/blog/2025-11-02-expected-utility/</guid><pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate></item><item><title>Latent Space COWBOYS: a VAE-BO method I can actually buy into!</title><link>https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I am generally pessimistic about BO (Bayesian optimization) methods which use
VAE embeddings as part of the model. Mostly this is because distance in a VAE's
latent space has no reason to correlate with distances in property space
(unless trained for it), and because training with labels is basically deep
kernel learning which usually overfits&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;. However, I recently came across the
paper "&lt;em&gt;Return of the Latent Space COWBOYS: Re-thinking the use of VAEs for
Bayesian Optimisation of Structured Spaces&lt;/em&gt;"&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; and quite liked the idea,
ending my long-standing streak of disliking every VAE-BO paper I read.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>opinion</category><category>research papers</category><guid>https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/</guid><pubDate>Sun, 05 Oct 2025 00:00:00 GMT</pubDate></item><item><title>The case for public Slack channels only (no DMs).</title><link>https://austintripp.ca/blog/2025-07-27-public-slack-channels/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Working at a company with a distributed team and hybrid work, a lot of work
gets done on Slack. Slack can be very noisy, and I used to wish that fewer
people would post in public channels, instead using direct messages (DMs).
However, I am starting to think that over the long run, defaulting to public
channels instead of DMs is best. Here, I try to explain why.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-07-27-public-slack-channels/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>opinion</category><guid>https://austintripp.ca/blog/2025-07-27-public-slack-channels/</guid><pubDate>Sun, 27 Jul 2025 00:00:00 GMT</pubDate></item><item><title>Punishing poor reviewers at CVPR</title><link>https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;p&gt;This year &lt;a href="https://cvpr.thecvf.com/"&gt;CVPR&lt;/a&gt; pledged to make all authors
participate in peer review, and reject papers from authors who wrote
low-quality reviews.&lt;sup id="fnref:ref"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/#fn:ref"&gt;1&lt;/a&gt;&lt;/sup&gt; Last week they &lt;a href="https://x.com/CVPR/status/1894853624200863958"&gt;confirmed on
Twitter&lt;/a&gt; that they followed
through with this and rejected 19 papers. Presumably this is a tiny fraction of
the overall papers submitted, but I hope this is an effective deterrent for
future authors. At the very least, I'm glad that &lt;em&gt;some&lt;/em&gt; major conference tried
something like this!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Update 2025-06-25&lt;/strong&gt;: NeurIPS is trying something similar now, see
&lt;a href="https://blog.neurips.cc/2025/05/02/responsible-reviewing-initiative-for-neurips-2025/"&gt;https://blog.neurips.cc/2025/05/02/responsible-reviewing-initiative-for-neurips-2025/&lt;/a&gt;.
In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reviewers who are also authors &lt;em&gt;will not be able to see their own papers'
  reviews until they submit their own reviews&lt;/em&gt;. This also extends to their
  co-authors.&lt;/li&gt;
&lt;li&gt;Once again, authors who are alos reviewers can have their own papers
  desk-rejected if they submit poor reviews.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall this seems like a good initiative, but I hope this doesn't cause people
to simply not review at all...&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:ref"&gt;
&lt;p&gt;&lt;a href="https://cvpr.thecvf.com/Conferences/2025/CVPRChanges"&gt;https://cvpr.thecvf.com/Conferences/2025/CVPRChanges&lt;/a&gt; &lt;a class="footnote-backref" href="https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/#fnref:ref" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>machine learning</category><category>opinion</category><category>peer review</category><guid>https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/</guid><pubDate>Tue, 04 Mar 2025 00:00:00 GMT</pubDate></item></channel></rss>
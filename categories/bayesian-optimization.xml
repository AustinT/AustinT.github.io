<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website (Posts about bayesian optimization)</title><link>https://austintripp.ca/</link><description></description><atom:link href="https://austintripp.ca/categories/bayesian-optimization.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Tue, 30 Dec 2025 14:24:10 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Latent Space COWBOYS: a VAE-BO method I can actually buy into!</title><link>https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I am generally pessimistic about BO (Bayesian optimization) methods which use
VAE embeddings as part of the model. Mostly this is because distance in a VAE's
latent space has no reason to correlate with distances in property space
(unless trained for it), and because training with labels is basically deep
kernel learning which usually overfits&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;. However, I recently came across the
paper "&lt;em&gt;Return of the Latent Space COWBOYS: Re-thinking the use of VAEs for
Bayesian Optimisation of Structured Spaces&lt;/em&gt;"&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; and quite liked the idea,
ending my long-standing streak of disliking every VAE-BO paper I read.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>opinion</category><category>research papers</category><guid>https://austintripp.ca/blog/2025-10-05-latent-space-cowboys/</guid><pubDate>Sun, 05 Oct 2025 00:00:00 GMT</pubDate></item><item><title>Chebyshev Scalarization Explained</title><link>https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been reading about multi-objective optimization recently.&lt;sup id="fnref:surprise"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/#fn:surprise"&gt;1&lt;/a&gt;&lt;/sup&gt;
Many papers state limitations of "linear scalarization" approaches,
mainly that it might not be able to represent all Pareto-optimal solutions
(if this sentence does not make sense to you, see &lt;a href="https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/#background-to-multi-objective-optimization"&gt;background&lt;/a&gt;).
Chebyshev scalarization is sometimes mentioned as an alternative which &lt;em&gt;can&lt;/em&gt; represent all solutions.
However, these papers mention it in passing without a proper explanation,
and I did not find a good explanation of it online.&lt;sup id="fnref:online"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/#fn:online"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;After doing a bit of my own research,&lt;sup id="fnref:gemini"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/#fn:gemini"&gt;3&lt;/a&gt;&lt;/sup&gt; I found that Chebyshev scalarization is actually not too complicated, so I thought &lt;em&gt;I&lt;/em&gt; would explain it online.
In this post, I:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Give definitions for Chebyshev scalarization (for both maximization and minimization)&lt;/li&gt;
&lt;li&gt;Give a simple proof that it can represent all Pareto-optimal solutions&lt;/li&gt;
&lt;li&gt;Explain its relationship to linear scalarization via $\ell_p$ norms.&lt;/li&gt;
&lt;li&gt;Give a geometric interpretation via an interactive visualization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>frontpage</category><category>machine learning</category><guid>https://austintripp.ca/blog/2025-05-12-chebyshev-scalarization/</guid><pubDate>Mon, 12 May 2025 00:00:00 GMT</pubDate></item><item><title>When should you expect Bayesian optimization to work well?</title><link>https://austintripp.ca/blog/2024-12-10-when-should-bo-work/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;As much as I believe in the potential of Bayesian optimization (BO) to be
useful for scientific discovery, after 4+ years I have seen many instances
where BO &lt;em&gt;does not&lt;/em&gt; work. In this post I explain a simple heuristic rule to
decide whether you should expect BO to work well or not.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-10-when-should-bo-work/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>speculation</category><guid>https://austintripp.ca/blog/2024-12-10-when-should-bo-work/</guid><pubDate>Tue, 10 Dec 2024 00:00:00 GMT</pubDate></item><item><title>Thoughts on Google Vizier</title><link>https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Vizier,
described in a &lt;a href="http://arxiv.org/abs/2408.11527"&gt;recent paper from Google&lt;/a&gt;,
is a black-box optimization algorithm deployed
for "numerous research and production systems at Google".
Allegedly, this one algorithm works well on a wide range of settings
(something which the "no-free-lunch-theorem" suggests might not be possible).
In this post I provide my thoughts on what key design decisions likely make this
algorithm work well.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>research papers</category><guid>https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/</guid><pubDate>Sun, 13 Oct 2024 00:00:00 GMT</pubDate></item></channel></rss>
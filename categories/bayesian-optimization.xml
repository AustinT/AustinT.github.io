<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website (Posts about bayesian optimization)</title><link>https://austintripp.ca/</link><description></description><atom:link href="https://austintripp.ca/categories/bayesian-optimization.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2024 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Mon, 14 Oct 2024 09:25:10 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Thoughts on Google Vizier</title><link>https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Vizier,
described in a &lt;a href="http://arxiv.org/abs/2408.11527"&gt;recent paper from Google&lt;/a&gt;,
is a black-box optimization algorithm deployed
for "numerous research and production systems at Google".
Allegedly, this one algorithm works well on a wide range of settings
(something which the "no-free-lunch-theorem" suggests might not be possible).
In this post I provide my thoughts on what key design decisions likely make this
algorithm work well.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><guid>https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/</guid><pubDate>Sat, 12 Oct 2024 23:00:00 GMT</pubDate></item></channel></rss>
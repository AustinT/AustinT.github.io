<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website</title><link>https://austintripp.ca/</link><description>Austin Tripp's personal website</description><atom:link href="https://austintripp.ca/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Thu, 27 Mar 2025 11:01:16 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Conceptual confusion about desirable outputs of reaction prediction models.</title><link>https://austintripp.ca/blog/2025-03-27-reaction-correctness/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;In the literature about machine learning for retrosynthesis, one line of work
tries to predict chemical reactions, either in the &lt;em&gt;forward direction&lt;/em&gt; (ie what
products will A + B form) or in the &lt;em&gt;backward direction&lt;/em&gt; (ie what reactants
could react to produce molecule C). Such models are often trained on datasets
of known reactions like Pistachio or USPTO, with the hope of generalizing to
new "correct" reactions. However, this formulation of the problem overlooks a
lot of subtleties about what makes a reaction "correct". In this post I will
present a more nuanced mental model which (hopefully) clarifies some
ambiguities.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-03-27-reaction-correctness/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>retrosynthesis</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-03-27-reaction-correctness/</guid><pubDate>Thu, 27 Mar 2025 00:00:00 GMT</pubDate></item><item><title>Punishing poor reviewers at CVPR</title><link>https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;p&gt;This year &lt;a href="https://cvpr.thecvf.com/"&gt;CVPR&lt;/a&gt; pledged to make all authors
participate in peer review, and reject papers from authors who wrote
low-quality reviews.&lt;sup id="fnref:ref"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/#fn:ref"&gt;1&lt;/a&gt;&lt;/sup&gt; Last week they &lt;a href="https://x.com/CVPR/status/1894853624200863958"&gt;confirmed on
Twitter&lt;/a&gt; that they followed
through with this and rejected 19 papers. Presumably this is a tiny fraction of
the overall papers submitted, but I hope this is an effective deterrent for
future authors. At the very least, I'm glad that &lt;em&gt;some&lt;/em&gt; major conference tried
something like this!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:ref"&gt;
&lt;p&gt;&lt;a href="https://cvpr.thecvf.com/Conferences/2025/CVPRChanges"&gt;https://cvpr.thecvf.com/Conferences/2025/CVPRChanges&lt;/a&gt; &lt;a class="footnote-backref" href="https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/#fnref:ref" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><category>machine learning</category><category>opinion</category><category>peer review</category><guid>https://austintripp.ca/blog/2025-03-04-punish-bad-reviewers/</guid><pubDate>Tue, 04 Mar 2025 00:00:00 GMT</pubDate></item><item><title>Why don't ML conferences provide reviewer instructions?</title><link>https://austintripp.ca/blog/2025-02-25-no-reviewer-instructions/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I remember when I first received an invitation to review papers for an ML
conference in late 2020. What surprised me most was &lt;em&gt;not&lt;/em&gt; that I was being
invited (even though that was a surprise, since I was just a second year PhD
student who had only just completed writing a paper myself). Instead, it was
the lack of instruction of how to assess the papers: essentially just "write
your reviews by date X", and "evaluate novelty, significance, soundness, etc".
In fact, in all the years since, I think I have &lt;em&gt;never&lt;/em&gt; received explicit
instructions for reviewing ML conference papers.&lt;sup id="fnref:instructions"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-02-25-no-reviewer-instructions/#fn:instructions"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-02-25-no-reviewer-instructions/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>peer review</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-02-25-no-reviewer-instructions/</guid><pubDate>Tue, 25 Feb 2025 00:00:00 GMT</pubDate></item><item><title>Alpha over LLMs</title><link>https://austintripp.ca/blog/2025-02-24-llm-alpha/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;p&gt;On a recent podcast, &lt;a href="https://www.kalzumeus.com/about/"&gt;Patrick McKenzie&lt;/a&gt;
mentioned the idea of "alpha over LLMs": does a publisher produce text with any
meaningful advantage over asking an LLM? I think this is an important question
for anybody trying to regularly write, even if the readership is small (eg this
blog). I interpret this as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;People should not put out content which is obviously wrong and can be
  corrected by an LLM (eg "I have theory X" where asking an LLM provides clear
  and convincing counter-arguments to X).&lt;/li&gt;
&lt;li&gt;People should also not put out content which is worse than the answer you get
  from asking an LLM (eg the same content but explained less clearly).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will generally try to uphold this principle in future blog posts.&lt;/p&gt;</description><category>announcement</category><category>blog</category><category>using large language models</category><guid>https://austintripp.ca/blog/2025-02-24-llm-alpha/</guid><pubDate>Mon, 24 Feb 2025 00:00:00 GMT</pubDate></item><item><title>Is offline model-based optimization a realistic problem? (I'm not convinced)</title><link>https://austintripp.ca/blog/2025-02-14-is-offline-mbo-realistic/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;div class="alert alert-info"&gt;
This is a "quickpost": a post which I have tried to write quickly, without very much editing/polishing.
For more details on quickposts, see
&lt;a href="https://austintripp.ca/blog/2025-02-11-lowering-quality/"&gt;this blog post&lt;/a&gt;.
&lt;/div&gt;

&lt;p&gt;Offline model-based optimization (OMBO in this post) is essentially 1-shot
optimization using a fixed dataset. You see data, do whatever you want, then
propose a batch of query points, which are then evaluated. Hopefully, one (or
most) of the query points are optimal (or near optimal). End of task.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-02-14-is-offline-mbo-realistic/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-02-14-is-offline-mbo-realistic/</guid><pubDate>Fri, 14 Feb 2025 00:00:00 GMT</pubDate></item><item><title>Experiment: more posts, lower quality</title><link>https://austintripp.ca/blog/2025-02-11-lowering-quality/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Since starting my new position at Valence, my efforts to write more on my blog have clearly been successful.&lt;sup id="fnref:4years"&gt;&lt;a class="footnote-ref" href="https://austintripp.ca/blog/2025-02-11-lowering-quality/#fn:4years"&gt;1&lt;/a&gt;&lt;/sup&gt;
However, my internal list of "things I would like to write a blog post about" is growing far faster than I am actually
able to write blog posts about things where I do think it is worth putting an opinion online.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-02-11-lowering-quality/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>announcement</category><category>blog</category><guid>https://austintripp.ca/blog/2025-02-11-lowering-quality/</guid><pubDate>Tue, 11 Feb 2025 00:00:00 GMT</pubDate></item><item><title>Stock responses about statistical significance for reviewing machine learning papers</title><link>https://austintripp.ca/blog/2025-02-11-peer-review-stat-tests/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;So many ML papers contain tables like&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Score(↑)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Baseline 1&lt;/td&gt;
&lt;td&gt;49.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Baseline 2&lt;/td&gt;
&lt;td&gt;49.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Baseline 3&lt;/td&gt;
&lt;td&gt;50.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Our super fancy SOTA method&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;50.1%&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;then say "results on the benchmark show that our method is state-of-the-art for task X."&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-02-11-peer-review-stat-tests/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>peer review</category><guid>https://austintripp.ca/blog/2025-02-11-peer-review-stat-tests/</guid><pubDate>Tue, 11 Feb 2025 00:00:00 GMT</pubDate></item><item><title>Hiring is hard: why good applicants without connections can get overlooked.</title><link>https://austintripp.ca/blog/2025-02-09-hiring-is-hard/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Knowing people is a great way to get hired. Nepotism is one obvious explanation
(aka people hire you because they like you, or to gain favors from people who
like you). I (along with most other people) think that nepotism is bad: it's
unfair, and gives jobs to people who are probably not that good at them.
However, it is a mistake to think that nepotism is the only reason why people
who are known get hired, and that this practice is always bad. Some better
reasons are:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-02-09-hiring-is-hard/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>employment</category><guid>https://austintripp.ca/blog/2025-02-09-hiring-is-hard/</guid><pubDate>Sun, 09 Feb 2025 00:00:00 GMT</pubDate></item><item><title>Reaction model scores are CRITICAL to multi-step retrosynthesis.</title><link>https://austintripp.ca/blog/2025-01-26-reaction-model-scores/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Machine-learning for retrosynthesis is a popular research topic. Popular
sub-topics include:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-26-reaction-model-scores/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>retrosynthesis</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-01-26-reaction-model-scores/</guid><pubDate>Sun, 26 Jan 2025 00:00:00 GMT</pubDate></item><item><title>Double checking that Gauche's fingerprint kernels are positive definite.</title><link>https://austintripp.ca/blog/2025-01-12-gauche-kernels-pd/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a href="https://github.com/leojklarner/gauche"&gt;GAUCHE&lt;/a&gt; is a library for Gaussian
processes in chemistry. I contributed a small amount to GAUCHE several years
ago but am not an active developer. I recently learned that some new
fingerprint kernels were added. In this post I examine whether these kernels
are positive definite (PD), and if there are any restrictions attached.&lt;/p&gt;
&lt;p&gt;Using a small set of lemmas (of which two were new to me), I am convinced that
all but two of the kernels are PD, &lt;em&gt;without being restricted to binary
vectors&lt;/em&gt;. The remaining 2 I am unsure of, but don't claim that they are &lt;em&gt;not&lt;/em&gt;
PD.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-12-gauche-kernels-pd/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><guid>https://austintripp.ca/blog/2025-01-12-gauche-kernels-pd/</guid><pubDate>Sun, 12 Jan 2025 00:00:00 GMT</pubDate></item></channel></rss>
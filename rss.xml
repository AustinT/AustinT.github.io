<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website</title><link>https://austintripp.ca/</link><description>Austin Tripp's personal website</description><atom:link href="https://austintripp.ca/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents ¬© 2025 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Sun, 05 Jan 2025 16:21:01 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>New Year's Resolutions for 2025</title><link>https://austintripp.ca/blog/2025-01-05-resolutions25/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Happy 2025! Here are a few goals I am setting for myself this year!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-05-resolutions25/"&gt;Read more‚Ä¶&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>personal development</category><guid>https://austintripp.ca/blog/2025-01-05-resolutions25/</guid><pubDate>Sun, 05 Jan 2025 00:00:00 GMT</pubDate></item><item><title>Review of NeurIPS 2024 and predictions for ML in 2025</title><link>https://austintripp.ca/blog/2025-01-01-neurips24-and-trends25/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I was fortunate to attend NeurIPS 2024, arguably the largest and most
influential machine learning conference in the world (thanks Valence for
sponsoring my trip üôè). In this post I will try to summarize what I learned at
NeurIPS, and cautiously make some predictions for the year ahead.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-01-neurips24-and-trends25/"&gt;Read more‚Ä¶&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-01-01-neurips24-and-trends25/</guid><pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate></item><item><title>Rules of scientific English writing for an international audience.</title><link>https://austintripp.ca/blog/2024-12-30-international-english/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Although English is the common language for international scientific
communication, most scientists are not native English speakers. To account for
this, I think that all scientists (especially native English speakers) should
try to write text which is easy to read for non-native speakers. I propose the
following rules for this:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-30-international-english/"&gt;Read more‚Ä¶&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>language</category><category>speculation</category><category>writing</category><guid>https://austintripp.ca/blog/2024-12-30-international-english/</guid><pubDate>Mon, 30 Dec 2024 00:00:00 GMT</pubDate></item><item><title>When should you expect Bayesian optimization to work well?</title><link>https://austintripp.ca/blog/2024-12-10-when-should-bo-work/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;As much as I believe in the potential of Bayesian optimization (BO) to be
useful for scientific discovery, after 4+ years I have seen many instances
where BO &lt;em&gt;does not&lt;/em&gt; work. In this post I explain a simple heuristic rule to
decide whether you should expect BO to work well or not.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-10-when-should-bo-work/"&gt;Read more‚Ä¶&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>speculation</category><guid>https://austintripp.ca/blog/2024-12-10-when-should-bo-work/</guid><pubDate>Tue, 10 Dec 2024 00:00:00 GMT</pubDate></item><item><title>What can eduroam teach us about building research infrastructure</title><link>https://austintripp.ca/blog/2024-12-01-eduroam/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Eduroam is a fantastic piece of academic infrastructure: students/researchers
from thousands of universities around the world can &lt;em&gt;automatically&lt;/em&gt; connect to
WiFi and any partner institutions using login details from their home
institution. To me it's surprising that it exists, given that it has many
characteristics of projects which academia is &lt;em&gt;terrible&lt;/em&gt; at accomplishing:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-01-eduroam/"&gt;Read more‚Ä¶&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>speculation</category><guid>https://austintripp.ca/blog/2024-12-01-eduroam/</guid><pubDate>Sun, 01 Dec 2024 00:00:00 GMT</pubDate></item><item><title>Scientific conferences as approximate Bayesian inference</title><link>https://austintripp.ca/blog/2024-11-17-conference-bayes/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Scientists should ideally form their beliefs based on evidence and update their
beliefs as new evidence arrives. Unfortunately, humans are far from perfect
Bayesian thinkers and therefore may struggle to do this properly. In this post
I explain how conferences help scientists perform better Bayesian inference.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-11-17-conference-bayes/"&gt;Read more‚Ä¶&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>speculation</category><guid>https://austintripp.ca/blog/2024-11-17-conference-bayes/</guid><pubDate>Sun, 17 Nov 2024 00:00:00 GMT</pubDate></item><item><title>Overview of the NSGA-II algorithm for multi-objective optimization</title><link>https://austintripp.ca/blog/2024-11-04-nsga-ii/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Nondominated sorting genetic algorithm version 2,
more commonly called NSGA-II, is a well-established genetic algorithm
(aka evolutionary algorithm)
for multi-objective optimization (MOO).
In this post I try to extract the key insights/lessons from this paper.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-11-04-nsga-ii/"&gt;Read more‚Ä¶&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>research papers</category><guid>https://austintripp.ca/blog/2024-11-04-nsga-ii/</guid><pubDate>Mon, 04 Nov 2024 00:00:00 GMT</pubDate></item><item><title>Advice for applying for a PhD in AI for science in 2024</title><link>https://austintripp.ca/blog/2024-10-27-ai4sci-phi/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;With the immense growth of AI for science (AI4sci for brevity), I imagine many
younger students are considering applying for PhDs in AI for science in this
application cycle. This post is my attempt to turn my 5 years of experience in
AI4sci into actionable advice for prospective PhD students.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-10-27-ai4sci-phi/"&gt;Read more‚Ä¶&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>PhD</category><category>speculation</category><guid>https://austintripp.ca/blog/2024-10-27-ai4sci-phi/</guid><pubDate>Sun, 27 Oct 2024 00:00:00 GMT</pubDate></item><item><title>Thoughts on Google Vizier</title><link>https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Vizier,
described in a &lt;a href="http://arxiv.org/abs/2408.11527"&gt;recent paper from Google&lt;/a&gt;,
is a black-box optimization algorithm deployed
for "numerous research and production systems at Google".
Allegedly, this one algorithm works well on a wide range of settings
(something which the "no-free-lunch-theorem" suggests might not be possible).
In this post I provide my thoughts on what key design decisions likely make this
algorithm work well.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/"&gt;Read more‚Ä¶&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>research papers</category><guid>https://austintripp.ca/blog/2024-10-13-vizier-bayesopt/</guid><pubDate>Sun, 13 Oct 2024 00:00:00 GMT</pubDate></item><item><title>Being 'data-driven' does not mean that you should use bad data.</title><link>https://austintripp.ca/blog/2024-10-09-data-driven-bad-data/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Relying on data rather than intuitions to make decisions is usually a good thing,
but is not always better.
When one needs to make a decision about things for which there is no good data
it might be better to rely on intuition rather than the best proxy available.
Here are some examples where I think an intuition-based approach can be better
than a data-driven approach (but still worse than a data-driven approach with good data):&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-10-09-data-driven-bad-data/"&gt;Read more‚Ä¶&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>decision making</category><category>speculation</category><guid>https://austintripp.ca/blog/2024-10-09-data-driven-bad-data/</guid><pubDate>Wed, 09 Oct 2024 00:00:00 GMT</pubDate></item></channel></rss>
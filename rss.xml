<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Austin Tripp's website</title><link>https://austintripp.ca/</link><description>Austin Tripp's personal website</description><atom:link href="https://austintripp.ca/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents ¬© 2025 &lt;a href="mailto:austin.james.tripp[at]gmail.com"&gt;Austin Tripp&lt;/a&gt; MIT License</copyright><lastBuildDate>Mon, 27 Jan 2025 11:40:15 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Reaction model scores are CRITICAL to multi-step retrosynthesis.</title><link>https://austintripp.ca/blog/2025-01-26-reaction-model-scores/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Machine-learning for retrosynthesis is a popular research topic. Popular
sub-topics include:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-26-reaction-model-scores/"&gt;Read more‚Ä¶&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>retrosynthesis</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-01-26-reaction-model-scores/</guid><pubDate>Sun, 26 Jan 2025 00:00:00 GMT</pubDate></item><item><title>Double checking that Gauche's fingerprint kernels are positive definite.</title><link>https://austintripp.ca/blog/2025-01-12-gauche-kernels-pd/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a href="https://github.com/leojklarner/gauche"&gt;GAUCHE&lt;/a&gt; is a library for Gaussian
processes in chemistry. I contributed a small amount to GAUCHE several years
ago but am not an active developer. I recently learned that some new
fingerprint kernels were added. In this post I examine whether these kernels
are positive definite (PD), and if there are any restrictions attached.&lt;/p&gt;
&lt;p&gt;Using a small set of lemmas (of which two were new to me), I am convinced that
all but two of the kernels are PD, &lt;em&gt;without being restricted to binary
vectors&lt;/em&gt;. The remaining 2 I am unsure of, but don't claim that they are &lt;em&gt;not&lt;/em&gt;
PD.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-12-gauche-kernels-pd/"&gt;Read more‚Ä¶&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><guid>https://austintripp.ca/blog/2025-01-12-gauche-kernels-pd/</guid><pubDate>Sun, 12 Jan 2025 00:00:00 GMT</pubDate></item><item><title>What ML researchers and users get wrong: optimistic assumptions</title><link>https://austintripp.ca/blog/2025-01-09-optimistic-ml-assumptions/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;ML is often done poorly, both by "ML experts" (by which I mean people who
understand the algorithms but not the data) and "ML users" (by which I mean
people who understand their data, but not the algorithms). I think the cause is
often over-optimism, although about different things:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-09-optimistic-ml-assumptions/"&gt;Read more‚Ä¶&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>speculation</category><guid>https://austintripp.ca/blog/2025-01-09-optimistic-ml-assumptions/</guid><pubDate>Thu, 09 Jan 2025 00:00:00 GMT</pubDate></item><item><title>New Year's Resolutions for 2025</title><link>https://austintripp.ca/blog/2025-01-05-resolutions25/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Happy 2025! Here are a few goals I am setting for myself this year!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-05-resolutions25/"&gt;Read more‚Ä¶&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>personal development</category><guid>https://austintripp.ca/blog/2025-01-05-resolutions25/</guid><pubDate>Sun, 05 Jan 2025 00:00:00 GMT</pubDate></item><item><title>Review of NeurIPS 2024 and predictions for ML in 2025</title><link>https://austintripp.ca/blog/2025-01-01-neurips24-and-trends25/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;I was fortunate to attend NeurIPS 2024, arguably the largest and most
influential machine learning conference in the world (thanks Valence for
sponsoring my trip üôè). In this post I will try to summarize what I learned at
NeurIPS, and cautiously make some predictions for the year ahead.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2025-01-01-neurips24-and-trends25/"&gt;Read more‚Ä¶&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>machine learning</category><category>speculation</category><guid>https://austintripp.ca/blog/2025-01-01-neurips24-and-trends25/</guid><pubDate>Wed, 01 Jan 2025 00:00:00 GMT</pubDate></item><item><title>Rules of scientific English writing for an international audience.</title><link>https://austintripp.ca/blog/2024-12-30-international-english/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Although English is the common language for international scientific
communication, most scientists are not native English speakers. To account for
this, I think that all scientists (especially native English speakers) should
try to write text which is easy to read for non-native speakers. I propose the
following rules for this:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-30-international-english/"&gt;Read more‚Ä¶&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>language</category><category>speculation</category><category>writing</category><guid>https://austintripp.ca/blog/2024-12-30-international-english/</guid><pubDate>Mon, 30 Dec 2024 00:00:00 GMT</pubDate></item><item><title>When should you expect Bayesian optimization to work well?</title><link>https://austintripp.ca/blog/2024-12-10-when-should-bo-work/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;As much as I believe in the potential of Bayesian optimization (BO) to be
useful for scientific discovery, after 4+ years I have seen many instances
where BO &lt;em&gt;does not&lt;/em&gt; work. In this post I explain a simple heuristic rule to
decide whether you should expect BO to work well or not.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-10-when-should-bo-work/"&gt;Read more‚Ä¶&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian optimization</category><category>machine learning</category><category>speculation</category><guid>https://austintripp.ca/blog/2024-12-10-when-should-bo-work/</guid><pubDate>Tue, 10 Dec 2024 00:00:00 GMT</pubDate></item><item><title>What can eduroam teach us about building research infrastructure</title><link>https://austintripp.ca/blog/2024-12-01-eduroam/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Eduroam is a fantastic piece of academic infrastructure: students/researchers
from thousands of universities around the world can &lt;em&gt;automatically&lt;/em&gt; connect to
WiFi and any partner institutions using login details from their home
institution. To me it's surprising that it exists, given that it has many
characteristics of projects which academia is &lt;em&gt;terrible&lt;/em&gt; at accomplishing:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-12-01-eduroam/"&gt;Read more‚Ä¶&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>speculation</category><guid>https://austintripp.ca/blog/2024-12-01-eduroam/</guid><pubDate>Sun, 01 Dec 2024 00:00:00 GMT</pubDate></item><item><title>Scientific conferences as approximate Bayesian inference</title><link>https://austintripp.ca/blog/2024-11-17-conference-bayes/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Scientists should ideally form their beliefs based on evidence and update their
beliefs as new evidence arrives. Unfortunately, humans are far from perfect
Bayesian thinkers and therefore may struggle to do this properly. In this post
I explain how conferences help scientists perform better Bayesian inference.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-11-17-conference-bayes/"&gt;Read more‚Ä¶&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>speculation</category><guid>https://austintripp.ca/blog/2024-11-17-conference-bayes/</guid><pubDate>Sun, 17 Nov 2024 00:00:00 GMT</pubDate></item><item><title>Overview of the NSGA-II algorithm for multi-objective optimization</title><link>https://austintripp.ca/blog/2024-11-04-nsga-ii/</link><dc:creator>Austin Tripp</dc:creator><description>&lt;div&gt;&lt;p&gt;Nondominated sorting genetic algorithm version 2,
more commonly called NSGA-II, is a well-established genetic algorithm
(aka evolutionary algorithm)
for multi-objective optimization (MOO).
In this post I try to extract the key insights/lessons from this paper.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://austintripp.ca/blog/2024-11-04-nsga-ii/"&gt;Read more‚Ä¶&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>research papers</category><guid>https://austintripp.ca/blog/2024-11-04-nsga-ii/</guid><pubDate>Mon, 04 Nov 2024 00:00:00 GMT</pubDate></item></channel></rss>
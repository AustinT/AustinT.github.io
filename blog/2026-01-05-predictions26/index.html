<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Predictions for ML/AI in 2026 (and 2025 predictions re-visited). | Austin Tripp's website</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://austintripp.ca/blog/2026-01-05-predictions26/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Austin Tripp">
<link rel="prev" href="../2026-01-05-resolutions26/" title="New Year's Resolutions for 2026 (and scoring 2025 resolutions)" type="text/html">
<link rel="next" href="../2026-01-25-model-centric-bo/" title="My model-centric view of Bayesian optimization" type="text/html">
<meta property="og:site_name" content="Austin Tripp's website">
<meta property="og:title" content="Predictions for ML/AI in 2026 (and 2025 predictions re-visited).">
<meta property="og:url" content="https://austintripp.ca/blog/2026-01-05-predictions26/">
<meta property="og:description" content="Last year I made a bunch of predictions about
ML, and since 2025 is over it's time
to grade myself and repeat this exercise.


This will be a lower effort version than last year's: partly because AI i">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2026-01-05T01:00:00Z">
<meta property="article:tag" content="_recent-highlight">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="speculation">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Austin Tripp's website</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Source</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../" class="nav-link">Home</a>
                </li>
<li class="nav-item">
<a href="../../cv/" class="nav-link">CV</a>
                </li>
<li class="nav-item">
<a href="../../research/" class="nav-link">Research</a>
                </li>
<li class="nav-item">
<a href="../../resources/" class="nav-link">Resources</a>
                </li>
<li class="nav-item">
<a href="../" class="nav-link">Blog</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Predictions for ML/AI in 2026 (and 2025 predictions re-visited).</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Austin Tripp
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2026-01-05T01:00:00Z" itemprop="datePublished" title="2026-01-05">2026-01-05</time></a>
            </p>
            
        <p class="sourceline"><a href="index.md" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>Last year <a href="../2025-01-01-neurips24-and-trends25/">I made a bunch of predictions about
ML</a>, and since 2025 is over it's time
to grade myself and repeat this exercise.</p>
<!-- TEASER_END -->

<p>This will be a lower effort version than last year's: partly because AI is
growing and I don't think I'm doing a good job keeping track of it, partly
because a lot of progress is happening behind closed doors of frontier labs (so
less info is available to me as an outsider), and partly because other people
have already made a bunch of good predictions.<sup id="fnref:recs"><a class="footnote-ref" href="#fn:recs">1</a></sup> Therefore my predictions
are neither very bold nor very original.</p>
<h3 id="grading-my-2025-predictions-quick-version">Grading my 2025 predictions (quick version)</h3>
<p>My 2025 predictions are from <a href="../2025-01-01-neurips24-and-trends25/">this blog
post</a>. I'll quickly give each one a
score (without rigorous research, apologies for being a bit sloppy).</p>
<h4 id="ai-scientist-predictions">AI scientist predictions</h4>
<p>My original predictions:</p>
<blockquote>
<ul>
<li>There will be many more "AI scientist" announcements / papers. Almost all of
  them will be "all-hype-no-substance" and not worth spending much time on.</li>
<li>The papers with substance will have a narrower scope (eg "AI scientist for
  designing better batteries"), including a narrow scope for the experiments
  available. However, there will be a decent number of such papers (probably
  ~10)</li>
<li>Biggest advance over 2024 AI scientists will be in literature search. There
  will be a tool like FutureHouse's
  <a href="https://github.com/Future-House/paper-qa">PaperQA</a> that is good enough to
  actually be worth using for developing research ideas, but <em>will not</em> be a
  full substitute for literature searches.</li>
<li>Somebody will start a proper study of whether an AI scientist can actually
  outperform a team of human scientists at a simple (but realistic) task.
  However, the study will not conclude in 2025 (maybe 2026)</li>
</ul>
</blockquote>
<p>Evaluation:</p>
<ul>
<li>There were a <em>huge number</em> of AI scientist papers (many of which were just
  "hype" in my opinion).</li>
<li>Many of the ones I liked more did focus on a particular area, although
  <a href="https://edisonscientific.com/articles/announcing-kosmos">Kosmos</a> defied my
  expectations and did interesting work on a wide scope of problems.</li>
<li>Literature search tools <em>did</em> advance a lot (eg Deep Research tools from
  OpenAI and Google). However, these tools aren't perfect and seem to generate
  a lot of "slop" (not too much to be useful, but too much to be a perfect
  substitute for human research).</li>
<li>No idea whether a study was done to compare human scientists an AI scientists
  on non-trivial tasks. I know some papers have compared humans and AI on
  hypothesis generation. I'll look out for this in 2026.</li>
</ul>
<p>I'll give myself 8/10 here.</p>
<h4 id="llms">LLMs</h4>
<p>2025 predictions:</p>
<blockquote>
<ul>
<li>LLMs can still be easily jailbroken (offense seems dominant).</li>
<li>Lots of engineering tricks can make transformer inference faster.</li>
<li>LLMs are found to be mediocre at more and more tasks where "mediocre"
  performance is very impressive to achieve but not enough to actually replace
  existing workflows with LLMs (eg chemical synthesis planning). In the process
  of assessing this, more and more task-specific benchmarks have been created
  (which will be useful for assessing progress later on).</li>
<li>On existing benchmarks, newer (and larger) LLMs perform better than older
  LLMs. Exactly what the "scaling hypothesis" predicts.</li>
<li>Because frontier labs do not share their training data, studies generally
  cannot give a definitive answer to the question "did the model do well on
  task X because it (or something very similar) was present in its training
  data"?</li>
</ul>
</blockquote>
<p>I think these all hold up, although these were not terribly difficult or
original predictions to make.</p>
<h4 id="foundation-models-for-biology">Foundation models for biology</h4>
<p>2025 predictions:</p>
<blockquote>
<ul>
<li>Lots more startups appear in this space</li>
<li>Some kind of preliminary but non-trivial achievement from an industry lab</li>
</ul>
</blockquote>
<p>Lots of people are doing "virtual cells" (including
<a href="https://arxiv.org/abs/2505.14613">Valence</a> üí™), not sure how many are startups
though. It feels like there was no "non-trivial achievement" (at least none
that I can remember now). I'll give myself 3/10 here.</p>
<h4 id="small-molecule-design">Small molecule design</h4>
<p>2025 predictions:</p>
<blockquote>
<ul>
<li>Field still feels "stalled", though papers will still be published at NeurIPS
  + similar conferences</li>
<li>More serious efforts in industry to deploy these techniques, with some
  success</li>
<li>Best places to look for innovation will be in the methods section of
  Science/Nature-oriented papers</li>
<li>At least one important innovation will <em>not</em> be published (so I guess we
  won't know about it directly)</li>
</ul>
</blockquote>
<p>Analysis: most of these predictions were not concrete and falsifiable, but
overall I agree with the predictions. I'll subjectively give myself 7/10
(noting of course that the last prediction is completely unverifiable).</p>
<h4 id="bayesian-optimization">Bayesian optimization</h4>
<p>2025 predictions:</p>
<blockquote>
<ul>
<li>More and more companies will derive "mundane utility" from BO</li>
<li>People compare BO to LLMs for decision-making. These comparisons will not be
  "fair" in that they will use a pretty vanilla BO setup without much tuning.</li>
<li>Despite a lot of potential, only a handful of groups will continue to do
  serious BO work (probably mostly the same people as before)</li>
</ul>
</blockquote>
<p>Analysis: overall seems true. Probably LLMs are being chosen over BO for
slightly more tasks than I expected, so I'll give myself 6/10.</p>
<h4 id="general-ai-powered-productivity-tools">General AI-powered productivity tools</h4>
<p>2025 predictions:</p>
<blockquote>
<ul>
<li>More researchers use LLM tools</li>
<li>More niche tools that save time (for example, something like really reliable
  sorting of priority emails would save a lot of email time)</li>
<li>Range of tasks where LLMs are useful increases</li>
</ul>
</blockquote>
<p>Analysis: these were fairly easy predictions to make. Definitely more
researchers use LLM tools. Niche tools are definitely there, but it feels like
we got "general" tools that feed context into the frontier models (eg cursor)
instead of "niche" tools. LLMs clearly just got more useful. I'll give myself
6/10.</p>
<h4 id="ai-safety-alignment">AI safety / alignment</h4>
<p>2025 prediction (just 1):</p>
<blockquote>
<ul>
<li>Trends continue: safety becomes more mainstream as LLMs become more powerful,
  and we still do not "solve" safety because it is an immensely hard problem</li>
</ul>
</blockquote>
<p>Analysis: seems true, 10/10.</p>
<h3 id="quick-2026-predictions">Quick 2026 predictions</h3>
<p>For now I will just make predictions on the level of increase (‚¨ÜÔ∏è) or decrease
(‚¨áÔ∏è) in importance / use / prominence of research directions or sub-fields.</p>
<ul>
<li>
<strong>AI scientists</strong>: ‚¨ÜÔ∏è</li>
<li>
<strong>AI drug discovery</strong>: ‚¨ÜÔ∏è</li>
<li>
<strong>LLMs</strong>: ‚¨ÜÔ∏è (but be on par with how important the AI community thinks they
  will be, which is <em>very</em> important)</li>
<li>
<strong>Bayesian optimization</strong>: ‚¨áÔ∏è (unfortunately üò¢, maybe with the exception of a
  few sub fields)</li>
<li>
<strong>Virtual cells / foundation models for biology</strong>: ‚¨ÜÔ∏è</li>
<li>
<strong>AI increasing everyday productivity</strong> ‚¨ÜÔ∏è</li>
</ul>
<p>Mostly these predictions are just "current trends will continue", so they
aren't very original.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:recs">
<p>I'll highlight predictions from the <a href="https://www.stateof.ai/2025-report-launch">State of AI report</a>.¬†<a class="footnote-backref" href="#fnref:recs" title="Jump back to footnote 1 in the text">‚Ü©</a></p>
</li>
</ol>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/machine-learning/" rel="tag">machine learning</a></li>
            <li><a class="tag p-category" href="../../categories/speculation/" rel="tag">speculation</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../2026-01-05-resolutions26/" rel="prev" title="New Year's Resolutions for 2026 (and scoring 2025 resolutions)">Previous post</a>
            </li>
            <li class="next">
                <a href="../2026-01-25-model-centric-bo/" rel="next" title="My model-centric view of Bayesian optimization">Next post</a>
            </li>
        </ul></nav></aside></article><!--End of body content--><footer id="footer"><div style="text-align: center;">
<a href="mailto:austin.james.tripp[at]gmail.com">Email</a> | 
<a href="https://github.com/AustinT">GitHub</a> | 
<a href="https://scholar.google.com/citations?user=WAvRaxMAAAAJ">Scholar</a> | 
<a href="https://bsky.app/profile/austinjtripp.bsky.social">Bluesky</a> | 
<a href="https://twitter.com/austinjtripp">Twitter/X</a> 
</div>
<br>
Website powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>.
Last updated 2026-02-01.
Contents ¬© 2026         Austin Tripp (MIT License). <br>
All opinions and statements on this site are my own (ie not my employer's).
<br></footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script src="../../assets/js/luxon.min.js"></script><!-- fancy dates --><script>
        luxon.Settings.defaultLocale = "en";
        fancydates(2, {"preset": false, "format": "yyyy-MM-dd HH:mm"});
        </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>

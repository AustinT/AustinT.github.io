<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Overview of the NSGA-II algorithm for multi-objective optimization | Austin Tripp's website</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://austintripp.ca/blog/2024-11-04-nsga-ii/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Austin Tripp">
<link rel="prev" href="../2024-10-27-ai4sci-phi/" title="Advice for applying for a PhD in AI for science in 2024" type="text/html">
<link rel="next" href="../2024-11-17-conference-bayes/" title="Scientific conferences as approximate Bayesian inference" type="text/html">
<meta property="og:site_name" content="Austin Tripp's website">
<meta property="og:title" content="Overview of the NSGA-II algorithm for multi-objective optimization">
<meta property="og:url" content="https://austintripp.ca/blog/2024-11-04-nsga-ii/">
<meta property="og:description" content="Nondominated sorting genetic algorithm version 2,
more commonly called NSGA-II, is a well-established genetic algorithm
(aka evolutionary algorithm)
for multi-objective optimization (MOO).
In this pos">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2024-11-04T00:00:00Z">
<meta property="article:tag" content="research papers">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Austin Tripp's website</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Source</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../" class="nav-link">Home</a>
                </li>
<li class="nav-item">
<a href="../../cv/" class="nav-link">CV</a>
                </li>
<li class="nav-item">
<a href="../../research/" class="nav-link">Research</a>
                </li>
<li class="nav-item">
<a href="../../resources/" class="nav-link">Resources</a>
                </li>
<li class="nav-item">
<a href="../" class="nav-link">Blog</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Overview of the NSGA-II algorithm for multi-objective optimization</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Austin Tripp
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2024-11-04T00:00:00Z" itemprop="datePublished" title="2024-11-04">2024-11-04</time></a>
            </p>
            
        <p class="sourceline"><a href="index.md" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>Nondominated sorting genetic algorithm version 2,
more commonly called NSGA-II, is a well-established genetic algorithm
(aka evolutionary algorithm)
for multi-objective optimization (MOO).
In this post I try to extract the key insights/lessons from this paper.</p>
<!-- TEASER_END -->

<p>Disclaimer: this blog post is almost certainly <em>not</em> the best piece of content
on the internet about NSGA-II.
I wrote it mainly to help myself understand the algorithm.
If you want to learn about the algorithm you may wish to read any one of the hundreds
of articles written about it since its initial publication 20+ years ago.</p>
<h3 id="preamble-why-should-i-care-about-nsga-ii">Preamble: why should I care about NSGA-II?</h3>
<p>Genetic algorithms (GAs) are very clearly not "cool" anymore,
and their shortcomings are well-known.
Despite this, NSGA-II seems to have been very widely-used.
As I am writing this post,
the paper proposing NSGA-II<sup id="fnref:Deb2002"><a class="footnote-ref" href="#fn:Deb2002">1</a></sup> has been cited
over 50000 times (according to Google scholar).
In fact, there are entire papers
(like <a href="https://link.springer.com/10.1007/s10462-023-10526-z">this one</a>)
which summarize the usage of this algorithm.
Clearly, something about NSGA-II <em>works</em> for real-world MOO,
or at least works well enough to be used more than most other algorithms.</p>
<h3 id="key-to-nsga-ii-a-thoughtful-partial-ordering">Key to NSGA-II: a thoughtful partial ordering</h3>
<p>Like other GAs, NSGA-II keeps a set of candidate solutions.
In each phase of the algorithm,
this set is first <em>grown</em> by 
randomly "mutating" and re-combining existing candidates,
then <em>pruned</em> to keep only the most promising candidates.
NSGA-II's contribution targets the second "pruning" step:
it proposes a way to select a subset of candidates which:</p>
<ul>
<li>Prioritizes non-dominated (aka Pareto-optimal) solutions</li>
<li>Respects constraints (if constraints exist)</li>
<li>Promotes diversity among candidates</li>
</ul>
<p>It accomplishes this by defining a <em>partial ordering</em>
$\prec_{n}$ over the candidate set (by our convention, lower is better).
It then uses $\prec_{n}$
to perform a <a href="https://en.wikipedia.org/wiki/Topological_sorting">topological sort</a>
of the candidate set
(ie an ordering $[x_1, \ldots, x_N]$ such that if $x_i\prec x_j$ then $i &lt; j$).
The first $P$ candidates from this set are chosen to be the next candidate set-
that's it.
All the logic to prioritize non-domination/diversity/constraint satisfaction goes
into the definition of $\prec_{n}$.</p>
<p>The original paper does not write out the entire algorithm for $\prec_{n}$,
so for clarity I will try to do so here.
The algorithm uses the following operators:</p>
<ul>
<li>
<em>objective domination</em> partial ordering $\prec_{o}$
(ie $x_i\prec_{o} x_j$ if $x_i$  differs from $x_j$ in at least one objective and is better than or equal to $x_j$ in <em>every</em> objective).</li>
<li>Scalar <em>constraint violation function</em> $g(x)$. $g(x)=0$ if $x$ satisfies the problem constraints, otherwise a positive value (higher values are worse).<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup>
</li>
<li>
<em>Crowding distance</em> $c(x)$ (how close $x$ is from other candidate solutions). Lower is better. Can be implemented in multiple ways (and this seems to be one of the most frequently varied parts of the algorithm)</li>
</ul>
<p>As far as I can tell,
the actual procedure to evaluate the statement $x_i\prec_{n} x_j$ (which can take the values <strong>true</strong>, <strong>false</strong><sup id="fnref:2"><a class="footnote-ref" href="#fn:2">3</a></sup>, or <strong>not-comparable (NC)</strong>) is:</p>
<ol>
<li>
<strong>Prioritize constraint satisfaction</strong>: if $g(x_i) &lt; g(x_j)$ return <strong>true</strong>. If $g(x_j) &lt; g(x_i)$: return <strong>false</strong>. Otherwise, go to next step.</li>
<li>
<strong>Check objectives</strong>: if $x_i \prec_{o} x_j$: return <strong>true</strong>. If $x_j \prec_o x_i$: return <strong>false</strong>. Otherwise, go to next step.</li>
<li>
<strong>Break ties by crowding</strong>: if $c(x_i) &lt; c(x_j)$: return <strong>true</strong>. If $c(x_j) &lt; c(x_i)$: return <strong>false</strong>. Otherwise, go to next step.</li>
<li>Return <strong>NC</strong>
</li>
</ol>
<p>Owing to the first condition,
the partial ordering $\prec_n$ will partition the candidates into two sets: those satisfying constraints (ie tied for $g(x)=0$), and those that do not.
Candidates <em>satisfying</em> the constraints are ordered first by non-domination ($\prec_o$), then by crowding for tie-breaking.
Candidates <em>not</em> satisfying the constraints will first be ordered by constraint violation, and the same procedure as other points
is used in case of a tie.</p>
<h3 id="why-does-nsga-ii-work-well">Why does NSGA-II work well?</h3>
<p>Put together, the partial ordering $\prec_n$ ensures a number of desirable properties:</p>
<ul>
<li>Candidates satisfying constraints are prioritized as much as possible</li>
<li>The current Pareto front is always preserved, if possible (this property is called <em>elitism</em> in the paper, probably because "elite" samples are always favored)</li>
<li>If the entire Pareto front cannot be preserved, it will try to eliminate points from "crowded" regions</li>
</ul>
<p>One way to think of NSGA-II is that it separates the candidates into a sequence of <em>non-dominated fronts</em>:
a first front wherein no point dominates any other, a second front whose points are only dominated by those in the first front,
a third front whose points are only dominated by those in the first two fronts, and so forth.
The heuristic of taking points from the first front, then from the second front, etc is simple and intuitive.</p>
<p>Importantly, NGSA-II <em>does not</em> require the user to input hyperparameters about how to trade-off diversity vs optimality,
which are probably difficult to tune.
The authors furthermore include a fast algorithm for non-dominated sorting
which scales with $O(MN^2)$ for $N$ candidates and $M$ objectives,
allowing the algorithm to be run with reasonably large populations.</p>
<h3 id="problems-with-nsga-ii">Problems with NSGA-II</h3>
<p>Reading a little bit into the literature (and asking ChatGPT),
it seems that NSGA-II struggles with problems
with many objectives (large $M$)
and in high dimensions.
Both struggles are understandable.
With many objectives the potential size of a non-dominated set could get very large,
potentially requiring a massive population.
Since NSGA-II's selection scales quadratically with population size, this can quickly become
infeasible.
Furthermore, in high dimensions it is likely difficult to design a good crowding function $c$.</p>
<h3 id="conclusions">Conclusions</h3>
<p>Ultimately, my takeaways from this paper are:</p>
<ul>
<li>How to trade-off between different objectives is a difficult challenge in MOO. NSGA-II shows that we can just sort candidates into sequential non-dominated fronts and prefer points from the outermost front as much as possible.</li>
<li>Using diversity only as a tie-breaker can make sense.</li>
<li>Using a partial ordering instead of a full ordering lets one avoid setting trade-off hyperparameters</li>
</ul>
<p>I would be curious if anybody has applied NSGA-II to molecules.
If I have time I might try to put it into my <a href="https://pypi.org/project/mol-ga/"><code>mol_ga</code></a> package.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:Deb2002">
<p><a href="https://ieeexplore.ieee.org/abstract/document/996017">https://ieeexplore.ieee.org/abstract/document/996017</a> <a class="footnote-backref" href="#fnref:Deb2002" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:1">
<p>Unconstrained problems are represented as $g(x)=0 \forall x$ <a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:2">
<p>implying $x_j\prec_{n} x_i$ <a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/research-papers/" rel="tag">research papers</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../2024-10-27-ai4sci-phi/" rel="prev" title="Advice for applying for a PhD in AI for science in 2024">Previous post</a>
            </li>
            <li class="next">
                <a href="../2024-11-17-conference-bayes/" rel="next" title="Scientific conferences as approximate Bayesian inference">Next post</a>
            </li>
        </ul></nav></aside><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article><!--End of body content--><footer id="footer"><div style="text-align: center;">
<a href="mailto:austin.james.tripp[at]gmail.com">Email</a> | 
<a href="https://github.com/AustinT">GitHub</a> | 
<a href="https://scholar.google.com/citations?user=WAvRaxMAAAAJ">Scholar</a> | 
<a href="https://bsky.app/profile/austinjtripp.bsky.social">Bluesky</a> | 
<a href="https://twitter.com/austinjtripp">Twitter/X</a> 
</div>
<br>
Website powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>.
Last updated 2025-04-01.
Contents © 2025         Austin Tripp (MIT License). <br>
All opinions and statements on this site are my own (ie not my employer's).
<br></footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script src="../../assets/js/luxon.min.js"></script><!-- fancy dates --><script>
        luxon.Settings.defaultLocale = "en";
        fancydates(2, {"preset": false, "format": "yyyy-MM-dd HH:mm"});
        </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
